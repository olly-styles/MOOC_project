{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "\n",
    "# Select all user ids\n",
    "engine = create_engine('mysql://root:toor@127.0.0.1/scigast')\n",
    "df_user_ids = pd.read_sql_query('SELECT anon_user_id FROM course_grades',engine)\n",
    "df_user_ids = df_user_ids.sort_values(by='anon_user_id')\n",
    "\n",
    "# Merge with the forum ids using the mapping\n",
    "df_forum_ids = pd.read_sql_query('SELECT anon_user_id,forum_user_id FROM hash_mapping',engine)\n",
    "df_id_mapping = df_forum_ids.merge(df_user_ids)\n",
    "\n",
    "#Select all the forum comment data\n",
    "df_forum_comments = pd.read_sql_query('SELECT forum_user_id,post_time,id\\\n",
    "                                      FROM forum_comments',engine)\n",
    "\n",
    "df_forum_comments = df_forum_comments.merge(df_id_mapping).drop('forum_user_id',axis=1)\n",
    "\n",
    "#Convert from unix time\n",
    "df_forum_comments['post_time'] = pd.to_datetime(df_forum_comments['post_time'],unit='s')\n",
    "\n",
    "#Select only the data during the course run time\n",
    "df_forum_comments = df_forum_comments[df_forum_comments.post_time >= pd.to_datetime('2013-07-10')]\n",
    "df_forum_comments = df_forum_comments[df_forum_comments.post_time < pd.to_datetime('2013-08-22')]\n",
    "\n",
    "# For timegrouper to work, the time must be the index\n",
    "df_forum_comments = df_forum_comments.set_index('post_time')\n",
    "\n",
    "#Lecture views for each user for each day\n",
    "df_forum_comments = df_forum_comments.groupby(by=['anon_user_id',pd.TimeGrouper(\"D\")]).count()\n",
    "\n",
    "#Start dates of each day (no offset)\n",
    "day_dates = pd.DataFrame(pd.date_range('2013-07-10', periods=42, freq='D'))\n",
    "\n",
    "# Create a new data frame \"cross join\" with all users and data combinations\n",
    "df_user_ids['TEMP'] = 0\n",
    "day_dates['TEMP'] = 0\n",
    "cross_join = df_user_ids.merge(day_dates,how='left',on='TEMP')\n",
    "cross_join.drop('TEMP',1,inplace=True)\n",
    "cross_join = cross_join.rename(columns={0: 'post_time'})\n",
    "\n",
    "# Merge the lecture views with the cross join tableand fill na so that every \n",
    "# ID / lecture day combination contains a value \n",
    "df_forum_comments = cross_join.merge(df_forum_comments.reset_index(), \\\n",
    "                                         on=['post_time','anon_user_id'],how='left')\\\n",
    "                                         .fillna(0)\n",
    "df_forum_comments = df_forum_comments.rename(columns={'id':'count'})\n",
    "\n",
    "# Pivot the table so that each day is a column. This is the first feature f1\n",
    "f1 = df_forum_comments.pivot('anon_user_id', 'post_time', 'count')\n",
    "\n",
    "# Convert days to weeks\n",
    "f1['04_w1'] = f1[f1.columns[np.arange(0,7)]].sum(axis=1)\n",
    "f1['04_w2'] = f1[f1.columns[np.arange(7,14)]].sum(axis=1)\n",
    "f1['04_w3'] = f1[f1.columns[np.arange(14,21)]].sum(axis=1)\n",
    "f1['04_w4'] = f1[f1.columns[np.arange(21,28)]].sum(axis=1)\n",
    "f1['04_w5'] = f1[f1.columns[np.arange(28,35)]].sum(axis=1)\n",
    "f1['04_w6'] = f1[f1.columns[np.arange(35,42)]].sum(axis=1)\n",
    "\n",
    "# And remove the day columns\n",
    "f1 = f1.drop(f1.columns[np.arange(0,42)],axis=1)\n",
    "\n",
    "# Save the feature to a pickle so the code does not have to be run again\n",
    "f1.to_pickle('../data/04_forumComments.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
